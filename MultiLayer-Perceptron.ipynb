{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import shutil # pour les dossiers\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrique(path):\n",
    "    files = os.listdir(path);\n",
    "    contenu = [];\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            openFile = open(path+file, \"r\");\n",
    "            contenu.append(json.loads(openFile.read())[\"Image\"]);\n",
    "            openFile.close();\n",
    "    return contenu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "chemin = \"./train/\";\n",
    "contenu = [];\n",
    "if not os.path.isdir(chemin):\n",
    "    print('Rajouter le dossier train dans le dossier courant :) ! ');\n",
    "else :\n",
    "    contenu = metrique(chemin);\n",
    "    df = pd.DataFrame(contenu)\n",
    "    # on laisse Species car c'est égale au nombre de classe\n",
    "    df.drop([\"Genus\",\"ClassId\",\"Family\",\"Vote\",\"Location\",\"Latitude\",\"Longitude\",\"Date\",\"Author\",\"Content\",\"MediaId\", \"LearnTag\", \"ImageId2014\",\"ObservationId2014\",\"YearInCLEF\",\"ObservationId\"], axis='columns', inplace=True)\n",
    "    df = df.drop_duplicates()\n",
    "    classe  = df.to_numpy();\n",
    "    print(len(classe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [];\n",
    "Y = [];\n",
    "files = os.listdir(\"./train\")\n",
    "for file in files:\n",
    "    if file.endswith('.jpg'):\n",
    "        X.append(file);\n",
    "        nameFile = file.split('.')[0];\n",
    "        for file_class in files:\n",
    "            nameFileAutre = file_class.split('.')[0];\n",
    "            if nameFile==nameFileAutre and file_class.endswith('.json'):\n",
    "                fichierSrc = open(\"./train/\"+file_class, \"r\");\n",
    "                contenu = fichierSrc.read();\n",
    "                monJson = json.loads(contenu)\n",
    "                Y.append(monJson[\"Image\"][\"Species\"])\n",
    "                break;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# on a bien une classe par image !\n",
    "if(len(X) == len(Y)):\n",
    "    print(\"OK\")\n",
    "else:\n",
    "    print(\"KO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Salix caprea L.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42, stratify=Y)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./MLP/train/Salix caprea L.30108.jpg\n",
      "30108.jpg\n"
     ]
    }
   ],
   "source": [
    "# Création des répertoires ! \n",
    "directory = \"MLP\"\n",
    "for classe in y_train : \n",
    "    if(not os.path.isdir('./MLP/train/'+classe)):\n",
    "        os.mkdir('./MLP/train/'+classe)\n",
    "        \n",
    "for classe in y_test : \n",
    "    if(not os.path.isdir('./MLP/val/'+classe)):\n",
    "        os.mkdir('./MLP/val/'+classe)\n",
    "        \n",
    "# on met les images dans les répertoires precédents\n",
    "\n",
    "# on supprime le contenu\n",
    "\n",
    "directorys=os.listdir('./MLP/train/')\n",
    "for i in range(0,len(directory)):\n",
    "    files=os.listdir('./MLP/train/'+directorys[i])\n",
    "    for j in range(0,len(files)):\n",
    "        os.remove('./MLP/train/'+directorys[i]+'/'+files[j])\n",
    "\n",
    "directorys=os.listdir('./MLP/val/')\n",
    "for i in range(0,len(directory)):\n",
    "    files=os.listdir('./MLP/val/'+directorys[i])\n",
    "    for j in range(0,len(files)):\n",
    "        os.remove('./MLP/val/'+directorys[i]+'/'+files[j])\n",
    "\n",
    "# on met le contenu\n",
    "shutil.copyfile('./train/'+X_train[0],'./MLP/train/'+y_train[0]+'/'+X_train[0])\n",
    "\n",
    "print('./MLP/train/'+y_train[0]+X_train[0])\n",
    "print(X_train[0])\n",
    "for i in range(len(X_train)):\n",
    "    shutil.copyfile('./train/'+X_train[i],'./MLP/train/'+y_train[i]+'/'+X_train[i])\n",
    "    \n",
    "for i in range(len(X_test)):\n",
    "    shutil.copyfile('./train/'+X_test[i],'./MLP/val/'+y_test[i]+'/'+X_test[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "data_dir = 'MLP'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "#print(pd.DataFrame(class_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP,self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(3*224*224,128), # (input_size = batch_size * image_size,hidden_layers)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64) # (hidden_layers,num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-02e696b7f6e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Set model to evaluate mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "mean_train_losses = []\n",
    "mean_valid_losses = []\n",
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_losses=[]\n",
    "    valid_losses=[]\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "            for images,labels in dataloaders[phase]:                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = loss_fn(outputs,labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "                train_losses.append(loss.item())\n",
    "                            \n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "        else:\n",
    "            with torch.no_grad():   # Set model to evaluate mode\n",
    "                for i, (images,labels) in dataloaders[phase]:\n",
    "                    outputs = model(images)\n",
    "                    loss = loss_fn(outputs,labels)\n",
    "                    \n",
    "                    valid_losses.append(loss.item())\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    total += labels.size(0)\n",
    "            mean_train_losses.append(np.mean(train_losses))\n",
    "            mean_valid_losses.append(np.mean(valid_losses))\n",
    "            \n",
    "            accuracy = 100*correct/total\n",
    "            valid_acc_list.append(accuracy)\n",
    "            print('epoch : {}, train loss : {:.4f}, valid loss : {:.4f}, valid acc : {:.2f}%'\\\n",
    "         .format(epoch+1, np.mean(train_losses), np.mean(valid_losses), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 2327\n",
      "    Root location: MLP/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(image_datasets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    evolution_accuracy = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            evolution_accuracy.append(epoch_acc)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    print(\"Evolution de l'accuracy pour savoir si on doit augmenter l'époch : \")\n",
    "    plt.plot(evolution_accuracy)\n",
    "    plt.ylabel('Evolution accuracy par epoch')\n",
    "    plt.show()\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 4.2163 Acc: 0.0138\n",
      "val Loss: 4.2187 Acc: 0.0113\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 4.2131 Acc: 0.0125\n",
      "val Loss: 4.2187 Acc: 0.0113\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 4.2091 Acc: 0.0142\n",
      "val Loss: 4.2187 Acc: 0.0113\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 4.2094 Acc: 0.0120\n",
      "val Loss: 4.2187 Acc: 0.0113\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 4.2129 Acc: 0.0107\n",
      "val Loss: 4.2187 Acc: 0.0113\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 4.2223 Acc: 0.0107\n",
      "val Loss: 4.2187 Acc: 0.0113\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 4.2142 Acc: 0.0120\n",
      "val Loss: 4.2187 Acc: 0.0113\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 4.2118 Acc: 0.0133\n",
      "val Loss: 4.2187 Acc: 0.0113\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 4.2120 Acc: 0.0120\n",
      "val Loss: 4.2187 Acc: 0.0113\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-777bcfa538c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-94-a0200b25377f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Master/donnees_avancees/env/lib/python3.5/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Master/donnees_avancees/env/lib/python3.5/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ft = MLP()\n",
    "#num_ftrs = model_ft.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "class_names = image_datasets['train'].classes\n",
    "#model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "#torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "best_model = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One param\n",
      "Parameter containing:\n",
      "tensor([[-0.4789,  0.4410,  0.2044, -0.2410],\n",
      "        [ 0.3769,  0.1502, -0.0799, -0.3023],\n",
      "        [-0.4483,  0.2311, -0.2060,  0.0248],\n",
      "        ...,\n",
      "        [ 0.1169,  0.4867, -0.0776,  0.2218],\n",
      "        [ 0.0521, -0.0844,  0.4051,  0.3249],\n",
      "        [-0.3128,  0.0269, -0.1078,  0.1951]], requires_grad=True)\n",
      "One param\n",
      "Parameter containing:\n",
      "tensor([ 4.6833e-01, -2.5645e-01, -1.1559e-02,  3.0567e-01, -2.5046e-01,\n",
      "         1.9443e-02, -1.0949e-01, -2.4415e-01,  4.8110e-02, -3.3466e-01,\n",
      "         3.5572e-01,  2.1433e-01, -4.7692e-01, -4.0853e-01,  3.1212e-01,\n",
      "        -1.6819e-02,  1.3692e-01,  4.4063e-01, -4.6919e-02, -1.4800e-01,\n",
      "        -4.0496e-02, -4.1938e-01,  1.6247e-01,  3.1832e-01,  2.6616e-01,\n",
      "         3.5101e-01, -2.6829e-01,  1.2898e-01, -4.0994e-01, -3.0156e-01,\n",
      "         6.8122e-02, -3.2371e-01,  1.0602e-01,  3.2798e-01,  3.4014e-01,\n",
      "        -4.2570e-02,  1.6644e-01,  3.3812e-01,  2.4287e-01,  1.1193e-01,\n",
      "         1.2993e-01,  5.0408e-02, -7.2067e-02, -2.4901e-01, -2.6844e-01,\n",
      "         3.9944e-01,  4.0326e-01,  1.3496e-01, -2.3583e-01, -2.9411e-01,\n",
      "        -4.3170e-01, -1.5919e-01, -2.3448e-01, -6.8792e-03, -4.8481e-02,\n",
      "         6.2661e-02, -4.1980e-01,  3.0842e-01, -2.2130e-01, -1.2568e-02,\n",
      "         2.9159e-01,  4.5857e-01, -7.4463e-03,  3.7204e-01, -4.5455e-01,\n",
      "         4.0475e-01,  4.7554e-01, -4.4420e-01, -2.1707e-01, -3.8444e-01,\n",
      "         2.1439e-01,  8.3265e-02, -2.1720e-01,  4.0546e-01, -4.9850e-01,\n",
      "         3.6981e-01, -2.5518e-01, -2.8138e-01, -8.5885e-02, -4.4940e-01,\n",
      "        -3.1190e-01, -1.1846e-01, -1.6640e-01, -2.7020e-01, -4.8596e-01,\n",
      "        -3.4236e-01, -1.9005e-01, -7.6902e-02, -1.6703e-01,  2.4423e-01,\n",
      "         4.6408e-01, -3.2220e-01, -8.9241e-02, -2.5257e-01,  9.3316e-02,\n",
      "         2.5763e-01,  1.3317e-01, -3.1833e-02,  2.3882e-02,  2.1452e-01,\n",
      "         1.3776e-01, -3.9661e-01, -2.4605e-01,  8.4786e-02, -3.1589e-01,\n",
      "         2.6525e-01,  4.1413e-01, -2.2609e-01, -3.2101e-01, -3.9559e-01,\n",
      "        -4.6082e-01,  1.6524e-01, -2.2116e-01,  2.3235e-01,  6.7772e-02,\n",
      "        -3.2813e-01, -4.9807e-01,  2.1606e-01, -3.0592e-01, -4.2320e-01,\n",
      "        -1.7230e-01,  2.4191e-01,  2.4265e-01, -3.1136e-01,  3.0238e-01,\n",
      "         3.5738e-01,  1.2773e-01, -4.3270e-01, -5.1656e-02,  4.0952e-01,\n",
      "         2.1448e-01,  3.5730e-01,  4.8803e-01,  2.6597e-01,  4.4288e-01,\n",
      "        -2.0190e-01, -2.1498e-01,  4.0389e-01, -2.4686e-01, -4.8545e-01,\n",
      "         4.4817e-01,  2.1658e-01,  3.1253e-01, -2.0012e-01, -3.0935e-01,\n",
      "        -2.0999e-01, -2.5056e-01, -1.4245e-01,  3.2580e-01,  2.9352e-03,\n",
      "        -4.4192e-01,  1.0054e-02,  4.2803e-01, -5.3766e-02, -7.2822e-02,\n",
      "        -2.5579e-01,  3.2003e-01, -3.7855e-01,  8.4971e-02,  1.9378e-01,\n",
      "        -2.2721e-01,  4.2603e-01,  4.6424e-01, -1.5494e-01, -5.0969e-02,\n",
      "         7.4715e-02, -3.4304e-01,  4.8512e-01, -3.3587e-01, -4.3144e-01,\n",
      "        -1.2609e-01, -9.4247e-02, -1.9265e-01, -1.1945e-01, -3.4293e-01,\n",
      "        -1.2901e-01, -2.1728e-01,  3.1114e-04,  3.9490e-01,  2.0896e-01,\n",
      "        -2.1714e-01,  4.1336e-01, -2.7389e-02,  2.5506e-01,  2.6958e-01,\n",
      "         4.5774e-01, -2.3347e-01,  6.2454e-02, -1.0961e-01, -4.7823e-01,\n",
      "         3.3030e-01,  4.3294e-01, -7.2676e-02,  1.8927e-01,  1.2454e-02,\n",
      "        -2.4186e-01,  4.1077e-01,  2.2180e-01, -8.5765e-02, -1.9933e-01,\n",
      "        -3.4631e-01, -2.6055e-01,  1.8634e-01, -4.6781e-01, -2.9766e-01,\n",
      "         2.8685e-01, -3.8377e-02,  3.6900e-02,  4.3247e-01, -2.3874e-01,\n",
      "         4.5718e-01, -2.4761e-01, -1.5326e-01, -3.0464e-01, -7.1295e-02,\n",
      "         3.9153e-01,  1.7859e-01,  2.1727e-01,  4.5687e-01, -3.0397e-01,\n",
      "        -4.2695e-01, -6.3264e-02,  1.0191e-01,  1.4337e-01, -2.5905e-01,\n",
      "         5.5811e-02,  1.9335e-01, -3.7593e-01, -3.7669e-01,  4.1522e-01,\n",
      "        -2.0533e-01, -2.3938e-01,  2.3712e-01, -4.6162e-01, -3.4849e-01,\n",
      "        -2.5700e-01, -4.3779e-01, -3.3568e-01,  1.5904e-02, -2.2352e-01,\n",
      "         2.0197e-01, -4.0986e-01,  4.9826e-01, -3.5528e-01, -7.2047e-02,\n",
      "        -4.4863e-01, -4.5824e-01, -3.3277e-01,  5.9567e-02,  3.6334e-01,\n",
      "         3.0399e-01, -8.8803e-02,  4.4183e-01,  3.4011e-01, -9.2000e-02,\n",
      "        -2.0252e-01, -3.2578e-01, -4.0556e-01,  2.2745e-01, -2.6704e-01,\n",
      "         4.3178e-01,  3.4365e-01,  4.5429e-01,  3.5447e-01,  4.2262e-02,\n",
      "         4.5710e-01,  3.4948e-01,  2.5887e-01,  1.7206e-01,  4.5193e-01,\n",
      "         4.6891e-01,  3.1486e-02, -2.3582e-01,  3.8384e-01, -4.6396e-02,\n",
      "        -2.7037e-01,  2.2144e-01,  7.2293e-03, -3.9987e-01, -2.1483e-01,\n",
      "        -4.3088e-01,  4.1169e-01,  3.1363e-01, -3.3583e-01,  2.6718e-02,\n",
      "        -6.5353e-02,  9.7950e-02, -1.4489e-01,  3.0525e-01, -1.3014e-01,\n",
      "         7.9349e-02, -1.2737e-01, -1.6401e-01, -2.1975e-01,  1.6621e-01,\n",
      "        -1.6766e-01, -6.5158e-02, -3.1161e-01,  2.5149e-01, -1.9515e-01,\n",
      "         4.9597e-01,  1.4397e-01,  4.0032e-01, -9.6850e-02, -4.7078e-01,\n",
      "         3.7272e-01,  2.9481e-02, -3.2407e-01, -2.3794e-01, -4.2052e-01,\n",
      "         4.3370e-01, -2.8349e-01, -1.8875e-01, -4.2751e-01,  1.9078e-01,\n",
      "         1.8328e-01, -4.5953e-01,  3.5345e-01,  6.2701e-02, -7.1249e-02,\n",
      "         2.4499e-01,  1.9654e-01, -9.5727e-02, -1.7750e-01, -3.3558e-01,\n",
      "         1.5703e-01, -1.2042e-01,  8.5383e-02,  2.4221e-01, -2.3522e-01,\n",
      "        -3.3577e-01, -3.7429e-01, -7.4060e-02,  6.0442e-03,  4.9762e-01,\n",
      "         4.2234e-01,  1.0727e-01,  1.0169e-02,  4.2560e-01,  4.0395e-01,\n",
      "        -2.3519e-01, -4.6808e-01, -4.1752e-01, -3.8315e-01, -9.0582e-02,\n",
      "         2.2095e-01, -2.9236e-01,  7.3374e-02,  2.3915e-01, -4.5903e-01,\n",
      "         3.2119e-01, -3.3180e-01,  2.0921e-01,  1.9619e-01, -4.5391e-01,\n",
      "        -1.1845e-01, -2.7421e-01,  3.2740e-01,  1.6627e-01, -2.5744e-01,\n",
      "        -1.7430e-02, -3.2653e-01,  3.5672e-01, -1.6106e-01,  4.6383e-01,\n",
      "        -2.9282e-01,  4.6614e-01,  8.3560e-02,  4.8200e-01,  4.4894e-01,\n",
      "         2.1212e-01,  3.6372e-01, -3.7695e-01, -2.8286e-01,  1.7725e-01,\n",
      "         4.3341e-01,  3.4952e-01, -1.0666e-01, -3.2448e-01,  3.0105e-01,\n",
      "         1.7380e-02, -4.0210e-01, -4.4756e-01,  1.8611e-01, -3.5777e-01,\n",
      "         4.8930e-01,  4.0943e-01,  4.0556e-01,  4.6213e-01,  3.1888e-01,\n",
      "         1.0884e-01, -7.5837e-02,  4.2907e-01, -4.1228e-01,  2.4809e-01,\n",
      "        -3.4780e-01, -4.1088e-01,  3.3720e-01,  2.6544e-01, -4.1052e-01,\n",
      "         2.8806e-01,  3.1796e-01, -5.8062e-02, -3.3202e-01,  1.5922e-01,\n",
      "         2.8003e-01,  4.1726e-01,  1.8850e-01,  1.5153e-01,  3.8370e-01,\n",
      "         4.0723e-01, -2.0787e-01,  1.4491e-01, -4.8383e-01, -1.8907e-01,\n",
      "         8.9659e-02, -2.9291e-02,  1.2125e-01, -1.5193e-01,  4.4972e-01,\n",
      "        -2.1486e-02,  2.7078e-01, -2.8942e-01,  2.4401e-01,  3.6471e-02,\n",
      "        -1.8254e-01, -4.0934e-01, -4.6311e-01,  1.5194e-01,  4.6358e-01,\n",
      "        -2.4416e-01,  2.8294e-01, -1.8435e-01, -3.3688e-01,  4.6664e-01,\n",
      "         2.8355e-01, -3.5242e-02, -2.7997e-01,  4.3406e-01, -9.4648e-02,\n",
      "         2.2777e-01, -2.5711e-01,  1.1656e-01, -4.9241e-01, -4.2135e-01,\n",
      "         5.7291e-02,  4.1000e-01,  4.9047e-01, -1.4595e-01, -4.7693e-01,\n",
      "        -1.2164e-01,  2.7504e-02, -3.7477e-01, -2.6272e-01, -1.9607e-02,\n",
      "        -2.5565e-01,  2.6290e-01,  3.3463e-01, -2.8308e-01,  2.9069e-01,\n",
      "        -4.4210e-01, -4.6234e-01, -2.0379e-01,  2.8077e-01, -3.9450e-01,\n",
      "        -4.0784e-01, -6.6385e-02,  2.9570e-01, -2.3845e-01,  4.0007e-01,\n",
      "        -3.6719e-01, -2.7565e-03,  1.1633e-01,  4.9320e-02, -3.6469e-01,\n",
      "        -2.4909e-01, -1.6944e-01, -3.4799e-01, -2.3177e-01, -7.2632e-02,\n",
      "        -4.1229e-01,  2.3224e-01, -8.3707e-02, -1.0334e-01, -5.1466e-02,\n",
      "         3.3033e-01,  1.6280e-01,  3.9484e-01, -2.9666e-01, -9.9188e-02,\n",
      "        -3.6613e-01,  3.7815e-01, -2.9740e-02,  3.2519e-01,  1.1053e-01,\n",
      "        -3.9644e-01,  4.0382e-01, -3.9255e-01, -1.7865e-01, -2.5953e-02,\n",
      "         1.0045e-01,  3.3164e-01, -3.9731e-01, -4.9259e-01, -3.0176e-01,\n",
      "        -1.3312e-02,  8.3774e-02,  2.0466e-01, -3.7724e-01, -1.4074e-02,\n",
      "        -3.2930e-01,  4.9788e-01,  1.4000e-01,  1.4661e-01, -4.0471e-01,\n",
      "         1.0574e-03,  1.5604e-01, -3.9420e-01, -3.4941e-01, -4.3546e-02,\n",
      "        -2.7296e-01,  4.9920e-01, -4.8867e-01,  3.5677e-01, -1.0060e-01,\n",
      "         1.3743e-01,  2.8420e-01, -3.7260e-01, -4.8796e-01,  4.3374e-02,\n",
      "         1.5228e-02,  3.8378e-01,  3.2604e-01,  3.8640e-01, -3.5958e-01,\n",
      "         1.5326e-01,  2.0221e-01,  2.1751e-01,  3.6662e-01, -3.2196e-01,\n",
      "        -2.2466e-01,  1.8996e-01, -1.2040e-01,  4.1334e-01, -1.8409e-01,\n",
      "        -3.1037e-01, -1.9946e-01,  2.2078e-01, -2.3627e-01, -5.9934e-02,\n",
      "        -4.4261e-01,  4.2327e-02,  4.1724e-01, -2.7241e-01, -2.8844e-01,\n",
      "        -4.2180e-01,  3.5615e-01, -9.5537e-02,  2.6310e-01,  2.0536e-01,\n",
      "        -2.9812e-01, -1.4089e-01,  2.1386e-01,  2.7105e-01,  4.7804e-01,\n",
      "        -4.9504e-01, -3.9160e-01, -3.7299e-01,  2.0124e-01, -3.4133e-01,\n",
      "         1.0191e-01, -1.4952e-01, -2.0318e-01, -4.9885e-01, -4.9170e-01,\n",
      "         5.3345e-02,  3.6214e-01, -5.7765e-02,  3.9778e-01,  2.2550e-01,\n",
      "        -1.5377e-02,  3.6806e-01, -6.2007e-04, -2.4333e-01, -9.4165e-02,\n",
      "         2.2915e-01, -3.2832e-01, -2.3141e-01,  3.7913e-01,  2.2721e-01,\n",
      "         4.6383e-01, -9.9343e-02,  3.5271e-01,  2.0334e-01,  2.4085e-01,\n",
      "        -3.9801e-01,  1.1818e-01,  4.9748e-01,  2.3216e-01,  2.7408e-01,\n",
      "        -4.0256e-01, -2.7420e-01, -2.1373e-01,  1.9805e-01,  1.9831e-01,\n",
      "        -1.4637e-01, -3.4774e-02,  1.3070e-01,  1.4495e-01, -2.7073e-01,\n",
      "         5.6747e-02,  2.3362e-01, -4.7310e-01, -1.4348e-01, -3.8278e-01,\n",
      "        -3.0747e-01,  3.2937e-01, -9.5799e-02, -2.0969e-01, -1.5643e-01,\n",
      "         3.3104e-01,  9.4777e-02,  1.1979e-01,  2.6591e-02, -4.6255e-01,\n",
      "        -2.5588e-01,  1.6726e-01, -2.7038e-01, -3.4749e-01,  8.2172e-02,\n",
      "         4.1704e-01,  3.4487e-01,  7.5987e-02, -3.7443e-01, -8.8456e-03,\n",
      "        -3.9498e-01, -3.4386e-02, -1.9733e-01, -1.4383e-02, -4.7991e-01,\n",
      "        -1.0119e-02,  1.6962e-02, -3.9386e-01,  1.9096e-01,  4.3056e-01,\n",
      "        -3.3053e-01,  2.8788e-03,  4.9317e-01, -1.9611e-01, -1.5817e-01,\n",
      "        -2.3439e-01,  4.4690e-01,  2.0411e-01,  2.7049e-01, -4.0767e-01,\n",
      "         6.4375e-03, -8.2653e-02,  1.2017e-01, -2.7319e-01, -3.4978e-01,\n",
      "        -2.4070e-01,  2.0057e-01, -4.1535e-01,  1.7683e-01,  3.0346e-01,\n",
      "         4.9467e-01, -2.1915e-02, -2.8095e-01, -4.3055e-01,  4.5998e-01,\n",
      "         6.9107e-02, -2.6979e-01, -3.5914e-01, -4.5024e-02,  3.9871e-01,\n",
      "        -2.0738e-01, -3.4506e-01, -4.8383e-01, -2.0043e-01, -3.5031e-01,\n",
      "         2.1413e-01,  7.8883e-02, -1.1752e-01,  2.1071e-01, -3.9508e-01,\n",
      "        -3.2363e-01, -3.3329e-01, -4.2186e-01,  2.3849e-01,  1.3259e-01,\n",
      "        -7.7443e-02,  1.0680e-01,  3.3204e-01, -6.0376e-02, -1.7183e-01,\n",
      "         2.5995e-01, -1.1493e-01, -4.3770e-01,  4.5953e-01,  1.5453e-01,\n",
      "        -9.1732e-02,  3.5205e-01, -8.8957e-03, -2.7621e-01, -7.0134e-02,\n",
      "        -4.7461e-01,  8.0952e-02, -2.0638e-01, -4.1591e-01, -3.6976e-01,\n",
      "         3.6489e-01, -2.3841e-01,  8.4858e-02, -3.9117e-01,  5.5524e-02,\n",
      "        -4.0829e-01,  2.0007e-01, -9.3394e-03, -4.6699e-01, -1.9786e-01,\n",
      "        -1.5532e-01,  4.7218e-01, -3.7710e-01,  3.7997e-01,  3.9157e-01,\n",
      "         3.8912e-01, -1.2210e-01,  2.7214e-01, -4.7624e-01,  8.4936e-02,\n",
      "        -5.6856e-02, -9.1406e-02,  4.1657e-01,  2.8351e-01,  1.4996e-01,\n",
      "        -4.5146e-01, -3.7792e-01, -3.4961e-01,  1.7537e-01, -4.2137e-01,\n",
      "         3.8462e-01, -2.4794e-01,  3.9293e-01, -2.8200e-01, -3.5408e-01,\n",
      "        -4.7878e-01,  3.7576e-01,  2.7541e-01,  3.2549e-02, -1.0668e-01,\n",
      "         6.8113e-02, -2.5962e-01,  1.5728e-01,  1.8222e-01, -2.7752e-02,\n",
      "        -3.2172e-02, -1.2607e-01, -3.9314e-01,  3.5682e-01, -9.4605e-02,\n",
      "        -1.3966e-01,  3.3598e-01,  4.5738e-03,  2.3962e-01, -3.9531e-01,\n",
      "        -3.3627e-01,  1.1243e-01, -4.7730e-01], requires_grad=True)\n",
      "One param\n",
      "Parameter containing:\n",
      "tensor([[ 0.0180,  0.0049,  0.0069,  ...,  0.0321,  0.0102,  0.0165],\n",
      "        [ 0.0348, -0.0161, -0.0256,  ...,  0.0011, -0.0095, -0.0024],\n",
      "        [ 0.0008,  0.0156, -0.0243,  ...,  0.0249, -0.0045, -0.0243],\n",
      "        ...,\n",
      "        [ 0.0183, -0.0148,  0.0275,  ..., -0.0037, -0.0321,  0.0251],\n",
      "        [-0.0213, -0.0117, -0.0268,  ..., -0.0169,  0.0304,  0.0077],\n",
      "        [-0.0079,  0.0245, -0.0133,  ...,  0.0202,  0.0332,  0.0315]],\n",
      "       requires_grad=True)\n",
      "One param\n",
      "Parameter containing:\n",
      "tensor([ 0.0036, -0.0067, -0.0189,  0.0095,  0.0336, -0.0292, -0.0206, -0.0093,\n",
      "        -0.0272, -0.0121,  0.0186, -0.0165, -0.0132,  0.0094,  0.0083,  0.0209,\n",
      "        -0.0347, -0.0274, -0.0131, -0.0241, -0.0288,  0.0329,  0.0006,  0.0206,\n",
      "        -0.0123, -0.0305,  0.0113, -0.0082,  0.0180,  0.0029,  0.0074,  0.0179,\n",
      "         0.0049,  0.0306, -0.0165,  0.0038,  0.0080,  0.0016, -0.0162, -0.0351,\n",
      "         0.0252,  0.0316, -0.0334, -0.0353, -0.0321,  0.0281, -0.0042, -0.0205,\n",
      "         0.0279,  0.0301], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.parameters():\n",
    "    print(\"One param\")\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
